--- linux-2.6.9/include/net/sctp/structs.h.sctp	2006-04-11 17:03:50.000000000 -0400
+++ linux-2.6.9/include/net/sctp/structs.h	2006-04-11 17:04:26.000000000 -0400
@@ -659,6 +659,7 @@
 	__u8 tsn_gap_acked;	/* Is this chunk acked by a GAP ACK? */
 	__u8 fast_retransmit;	 /* Is this chunk fast retransmitted? */
 	__u8 tsn_missing_report; /* Data chunk missing counter. */
+	__u8 data_accepted; 	/* At least 1 chunk in this packet accepted */
 };
 
 void sctp_chunk_hold(struct sctp_chunk *);
--- linux-2.6.9/net/sctp/inqueue.c.sctp	2004-10-18 17:54:39.000000000 -0400
+++ linux-2.6.9/net/sctp/inqueue.c	2006-04-11 17:04:26.000000000 -0400
@@ -154,6 +154,7 @@
 		/* This is the first chunk in the packet.  */
 		chunk->singleton = 1;
 		ch = (sctp_chunkhdr_t *) chunk->skb->data;
+		chunk->data_accepted = 0;
 	}
 
         chunk->chunk_hdr = ch;
--- linux-2.6.9/net/sctp/sm_statefuns.c.sctp	2006-04-11 17:03:50.000000000 -0400
+++ linux-2.6.9/net/sctp/sm_statefuns.c	2006-04-11 17:04:26.000000000 -0400
@@ -4646,7 +4646,10 @@
 	int tmp;
 	__u32 tsn;
 	int account_value;
+	__u16 num_gaps;
+	struct sctp_tsnmap *map = (struct sctp_tsnmap *)&asoc->peer.tsn_map;
 	struct sock *sk = asoc->base.sk;
+	int rcvbuf_over = 0;
 
 	data_hdr = chunk->subh.data_hdr = (sctp_datahdr_t *)chunk->skb->data;
 	skb_pull(chunk->skb, sizeof(sctp_datahdr_t));
@@ -4658,9 +4661,14 @@
 
 	/*
 	 * if we are established, and we have used up our receive
-	 * buffer memory, drop the frame
+	 * buffer memory, think about droping the frame
+	 * Note that we have an opportunity to improve performance here
+	 * if we accept one chunk from an skbuf, we have to keep all the memory 
+	 * of that skbuff around until the chunk is read into user space
+	 * therefore, once we accept 1 chunk we may as well accept all remaining 	
+	 * chunks in the skbuff.  The data_accepted flag helps us do that
 	 */
-	if (asoc->state == SCTP_STATE_ESTABLISHED) {
+	if ((asoc->state == SCTP_STATE_ESTABLISHED) && (!chunk->data_accepted)) {
 		/*
 		 * If the receive buffer policy is 1, then each
 		 * association can allocate up to sk_rcvbuf bytes
@@ -4671,9 +4679,27 @@
 			account_value = atomic_read(&asoc->rmem_alloc);
 		else
 			account_value = atomic_read(&sk->sk_rmem_alloc);
-
-		if (account_value > sk->sk_rcvbuf)
-			return SCTP_IERROR_IGNORE_TSN;
+		if (account_value > sk->sk_rcvbuf) {
+			
+			/*
+			 * We need to make forward progress, even when we are
+			 * under memory pressure, so we always allow the 
+			 * next tsn after the ctsn ack point to be accepted.
+			 * This lets us avoid deadlocks in which we have to 
+			 * drop frames that would otherwise let us drain the 
+			 * receive queue
+			 */
+			if ((sctp_tsnmap_get_ctsn(map) + 1) != tsn)
+				return SCTP_IERROR_IGNORE_TSN;
+
+			/*
+			 * we're going to accept the frame
+			 * but we should renege to make space for it
+			 * this will send us down that path later
+			 * in this function
+			 */
+			rcvbuf_over = 1;
+		}
 	}
 
 	/* Process ECN based congestion.
@@ -4721,6 +4747,7 @@
 	datalen -= sizeof(sctp_data_chunk_t);
 
 	deliver = SCTP_CMD_CHUNK_ULP;
+	chunk->data_accepted = 1;
 
 	/* Think about partial delivery. */
 	if ((datalen >= asoc->rwnd) && (!asoc->ulpq.pd_mode)) {
@@ -4737,7 +4764,8 @@
 	 * large spill over.
 	 */
 	if (!asoc->rwnd || asoc->rwnd_over ||
-	    (datalen > asoc->rwnd + asoc->frag_point)) {
+	    (datalen > asoc->rwnd + asoc->frag_point) ||
+	    rcvbuf_over) {
 
 		/* If this is the next TSN, consider reneging to make
 		 * room.   Note: Playing nice with a confused sender.  A
@@ -4745,8 +4773,8 @@
 		 * space and in the future we may want to detect and
 		 * do more drastic reneging.
 		 */
-		if (sctp_tsnmap_has_gap(&asoc->peer.tsn_map) &&
-		    (sctp_tsnmap_get_ctsn(&asoc->peer.tsn_map) + 1) == tsn) {
+		if (sctp_tsnmap_has_gap(map) &&
+		    (sctp_tsnmap_get_ctsn(map) + 1) == tsn) {
 			SCTP_DEBUG_PRINTK("Reneging for tsn:%u\n", tsn);
 			deliver = SCTP_CMD_RENEGE;
 		} else {